{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1ptHsRKQqNmTfppUsDiO1B8psn5Ycazku",
      "authorship_tag": "ABX9TyMIWVsEMj65r0y3ebZAl+d+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alan240124/Alan/blob/main/Ativ_Dataloader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wduTtwWoKCe5"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from glob import glob\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from tqdm import tqdm\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "# arquivo data.py\n",
        "class Data(Dataset):\n",
        "    def __init__(self, image_dir: str, split: str, transform=None) -> None:\n",
        "        # criar seu construtor\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        # retornar a quantidade de dados\n",
        "\n",
        "    def __getitem__(self, idx: int) -> tuple:\n",
        "        # retornar image/labels/boox/mask...\n",
        "\n",
        "class Dataloader:\n",
        "    def __init__(self, batch_size: int, shuffle: bool, size: int, subset: int = 0, description: bool = False) -> None:\n",
        "        # construtor do dataloader\n",
        "\n",
        "    def compose(self):\n",
        "        # retornar o compose\n",
        "\n",
        "    def get_dataloader(self, split: str) -> DataLoader:\n",
        "        # retornar o dataloader baseado no split\n",
        "\n",
        "    # def get_train_dataloader(self) -> DataLoader: return self.get_dataloader('train')\n",
        "    # def get_val_dataloader(self) -> DataLoader: return self.get_dataloader('val')\n",
        "    # def get_test_dataloader(self) -> DataLoader: return self.get_dataloader('test')\n",
        "\n",
        "  # arquivo main.py\n",
        "if __name__ == '__main__':\n",
        "    dataloader = SGHIST.Dataloader(batch_size=2, size=512, shuffle=True, description=True)\n",
        "\n",
        "    train_dataloader = dataloader.get_train_dataloader()\n",
        "    # val_dataloader = dataloader.get_val_dataloader()\n",
        "    # test_dataloader = dataloader.get_test_dataloader()\n",
        "\n",
        "    EPOCHS = 10\n",
        "    for epoch in range(0, EPOCHS):\n",
        "        for image, mask in train_dataloader:\n",
        "            image = image.detach().cpu().numpy()[0].transpose(1, 2, 0)\n",
        "            mask = mask.detach().cpu().numpy()[0]\n",
        "            cv2.imshow('image', image)\n",
        "            cv2.imshow('mask', mask)\n",
        "            if cv2.waitKey(1) == ord('q'):\n",
        "                break\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from glob import glob\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from tqdm import tqdm\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# arquivo data.py\n",
        "class Data(Dataset):\n",
        "    def __init__(self, image_dir: str, split: str, transform=None) -> None:\n",
        "        self.image_dir = image_dir\n",
        "        self.split = split\n",
        "        self.transform = transform\n",
        "        self.images = glob(f\"{image_dir}/{split}/*.jpg\")  # Exemplo, ajuste o caminho conforme necessário\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> tuple:\n",
        "        # Carregar imagem e rótulo, aplicar transformações\n",
        "        image_path = self.images[idx]\n",
        "        # Carregar e processar image, mask conforme o necessário\n",
        "        return image, mask\n",
        "\n",
        "class Dataloader:\n",
        "    def __init__(self, batch_size: int, shuffle: bool, size: int, subset: int = 0, description: bool = False) -> None:\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.size = size\n",
        "        self.subset = subset\n",
        "        self.description = description\n",
        "\n",
        "    def compose(self):\n",
        "        return A.Compose([\n",
        "            A.Resize(self.size, self.size),\n",
        "            A.Normalize(),\n",
        "            ToTensorV2()\n",
        "        ])\n",
        "\n",
        "    def get_dataloader(self, split: str) -> DataLoader:\n",
        "        dataset = Data(image_dir=\"path/to/images\", split=split, transform=self.compose())\n",
        "        return DataLoader(dataset, batch_size=self.batch_size, shuffle=self.shuffle)\n",
        "\n",
        "    def get_train_dataloader(self) -> DataLoader:\n",
        "        return self.get_dataloader('train')\n",
        "\n",
        "    def get_val_dataloader(self) -> DataLoader:\n",
        "        return self.get_dataloader('val')\n",
        "\n",
        "    def get_test_dataloader(self) -> DataLoader:\n",
        "        return self.get_dataloader('test')\n",
        "\n",
        "# arquivo main.py\n",
        "if __name__ == '__main__':\n",
        "    dataloader = Dataloader(batch_size=2, size=512, shuffle=True, description=True)\n",
        "\n",
        "    train_dataloader = dataloader.get_train_dataloader()\n",
        "\n",
        "    EPOCHS = 10\n",
        "    for epoch in range(EPOCHS):\n",
        "        for image, mask in train_dataloader:\n",
        "            image = image.detach().cpu().numpy()[0].transpose(1, 2, 0)\n",
        "            mask = mask.detach().cpu().numpy()[0]\n",
        "            plt.imshow(image)\n",
        "            plt.show()\n",
        "            plt.imshow(mask, cmap='gray')\n",
        "            plt.show()\n",
        "            # if cv2.waitKey(1) == ord('q'):\n",
        "            #     break"
      ],
      "metadata": {
        "id": "8ijLkhTCqIO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "class HeartDataset(Dataset):\n",
        "    def __init__(self, image_dir, mask_dir, transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.mask_dir = mask_dir\n",
        "        self.transform = transform\n",
        "        self.image_files = sorted(os.listdir(image_dir))\n",
        "        self.mask_files = sorted(os.listdir(mask_dir))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = os.path.join(self.image_dir, self.image_files[idx])\n",
        "        mask_path = os.path.join(self.mask_dir, self.mask_files[idx])\n",
        "\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "        mask = Image.open(mask_path).convert(\"L\")\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "            mask = self.transform(mask)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "image_dir = 'dataset/images'\n",
        "mask_dir = 'dataset/masks'\n",
        "\n",
        "heart_dataset = HeartDataset(image_dir=image_dir, mask_dir=mask_dir, transform=transform)\n",
        "dataloader = DataLoader(heart_dataset, batch_size=4, shuffle=True, num_workers=2)\n",
        "\n",
        "for batch_idx, (images, masks) in enumerate(dataloader):\n",
        "    print(f\"Lote {batch_idx + 1}\")\n",
        "    print(f\"Imagens: {images.size()}\")\n",
        "    print(f\"Máscaras: {masks.size()}\")\n"
      ],
      "metadata": {
        "id": "fSoVZQrtYguu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from glob import glob\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from tqdm import tqdm\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# arquivo data.py\n",
        "class Data(Dataset):\n",
        "    def __init__(self, image_dir: str, split: str, transform=None) -> None:\n",
        "        self.image_dir = image_dir\n",
        "        self.split = split\n",
        "        self.transform = transform\n",
        "        self.images = glob(f\"{image_dir}/{split}/images/*.jpg\")  # Ajuste conforme o caminho correto\n",
        "        self.masks = glob(f\"{image_dir}/{split}/masks/*.jpj\")  # Ajuste conforme o caminho correto\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> tuple:\n",
        "        image_path = self.images[idx]\n",
        "        mask_path = self.masks[idx]\n",
        "\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        if self.transform:\n",
        "            transformed = self.transform(image=image, mask=mask)\n",
        "            image = transformed[\"image\"]\n",
        "            mask = transformed[\"mask\"]\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "class Dataloader:\n",
        "    def __init__(self, batch_size: int, shuffle: bool, size: int, subset: int = 0, description: bool = False) -> None:\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.size = size\n",
        "        self.subset = subset\n",
        "        self.description = description\n",
        "\n",
        "    def compose(self):\n",
        "        return A.Compose([\n",
        "            A.Resize(self.size, self.size),\n",
        "            A.Normalize(),\n",
        "            ToTensorV2()\n",
        "        ])\n",
        "\n",
        "    def get_dataloader(self, split: str) -> DataLoader:\n",
        "        dataset = Data(image_dir=\"path/to/images\", split=split, transform=self.compose())\n",
        "\n",
        "        # Usar apenas um subset, se especificado\n",
        "        if self.subset > 0:\n",
        "            indices = list(range(len(dataset)))\n",
        "            subset_indices = indices[:self.subset]\n",
        "            dataset = Subset(dataset, subset_indices)\n",
        "\n",
        "        return DataLoader(dataset, batch_size=self.batch_size, shuffle=self.shuffle)\n",
        "\n",
        "    def get_train_dataloader(self) -> DataLoader:\n",
        "        return self.get_dataloader('train')\n",
        "\n",
        "    def get_val_dataloader(self) -> DataLoader:\n",
        "        return self.get_dataloader('val')\n",
        "\n",
        "    def get_test_dataloader(self) -> DataLoader:\n",
        "        return self.get_dataloader('test')\n",
        "\n",
        "# arquivo main.py\n",
        "if __name__ == '__main__':\n",
        "    dataloader = Dataloader(batch_size=2, size=512, shuffle=True, description=True)\n",
        "\n",
        "    train_dataloader = dataloader.get_train_dataloader()\n",
        "\n",
        "    EPOCHS = 10\n",
        "    for epoch in range(EPOCHS):\n",
        "        for image, mask in train_dataloader:\n",
        "            image_np = image.detach().cpu().numpy()[0].transpose(1, 2, 0)\n",
        "            mask_np = mask.detach().cpu().numpy()[0]\n",
        "\n",
        "            plt.figure(figsize=(10, 5))\n",
        "            plt.subplot(1, 2, 1)\n",
        "            plt.imshow(image_np)\n",
        "            plt.title(\"Image\")\n",
        "            plt.axis('off')\n",
        "\n",
        "            plt.subplot(1, 2, 2)\n",
        "            plt.imshow(mask_np, cmap='gray')\n",
        "            plt.title(\"Mask\")\n",
        "            plt.axis('off')\n",
        "\n",
        "            plt.show()"
      ],
      "metadata": {
        "id": "d-RMRZiQwO8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5Wz8Kvfk33tG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from glob import glob\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from tqdm import tqdm\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# arquivo data.py\n",
        "class Data(Dataset):\n",
        "    def __init__(self, image_dir: str, split: str, transform=None) -> None:\n",
        "        self.image_dir = image_dir\n",
        "        self.split = split\n",
        "        self.transform = transform\n",
        "        self.images = sorted(glob(f\"{image_dir}/{split}/images/*.jpg\"))  # Ordenar para garantir correspondência\n",
        "        self.masks = sorted(glob(f\"{image_dir}/{split}/masks/*.png\"))    # Ordenar para garantir correspondência\n",
        "\n",
        "        # Verificação de correspondência\n",
        "        if len(self.images) == 0:\n",
        "            raise ValueError(f\"Nenhuma imagem encontrada no diretório: {image_dir}/{split}/images/\")\n",
        "        if len(self.masks) == 0:\n",
        "            raise ValueError(f\"Nenhuma máscara encontrada no diretório: {image_dir}/{split}/masks/\")\n",
        "        if len(self.images) != len(self.masks):\n",
        "            raise ValueError(\"O número de imagens e máscaras não corresponde.\")\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> tuple:\n",
        "        image_path = self.images[idx]\n",
        "        mask_path = self.masks[idx]\n",
        "\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        if self.transform:\n",
        "            transformed = self.transform(image=image, mask=mask)\n",
        "            image = transformed[\"image\"]\n",
        "            mask = transformed[\"mask\"]\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "class Dataloader:\n",
        "    def __init__(self, batch_size: int, shuffle: bool, size: int, subset: int = 0, description: bool = False) -> None:\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.size = size\n",
        "        self.subset = subset\n",
        "        self.description = description\n",
        "\n",
        "    def compose(self):\n",
        "        return A.Compose([\n",
        "            A.Resize(self.size, self.size),\n",
        "            A.Normalize(),\n",
        "            ToTensorV2()\n",
        "        ])\n",
        "\n",
        "    def get_dataloader(self, split: str) -> DataLoader:\n",
        "        dataset = Data(image_dir=\"path/to/images\", split=split, transform=self.compose())\n",
        "\n",
        "        # Usar apenas um subset, se especificado\n",
        "        if self.subset > 0:\n",
        "            indices = list(range(len(dataset)))\n",
        "            subset_indices = indices[:self.subset]\n",
        "            dataset = Subset(dataset, subset_indices)\n",
        "\n",
        "        return DataLoader(dataset, batch_size=self.batch_size, shuffle=self.shuffle)\n",
        "\n",
        "    def get_train_dataloader(self) -> DataLoader:\n",
        "        return self.get_dataloader('train')\n",
        "\n",
        "    def get_val_dataloader(self) -> DataLoader:\n",
        "        return self.get_dataloader('val')\n",
        "\n",
        "    def get_test_dataloader(self) -> DataLoader:\n",
        "        return self.get_dataloader('test')\n",
        "\n",
        "# arquivo main.py\n",
        "if __name__ == '__main__':\n",
        "    dataloader = Dataloader(batch_size=2, size=512, shuffle=True, description=True)\n",
        "\n",
        "    train_dataloader = dataloader.get_train_dataloader()\n",
        "\n",
        "    EPOCHS = 10\n",
        "    for epoch in range(EPOCHS):\n",
        "        for image, mask in train_dataloader:\n",
        "            image_np = image.cpu().numpy()[0].transpose(1, 2, 0)\n",
        "            mask_np = mask.cpu().numpy()[0]\n",
        "\n",
        "            plt.figure(figsize=(10, 5))\n",
        "            plt.subplot(1, 2, 1)\n",
        "            plt.imshow(image_np)\n",
        "            plt.title(\"Image\")\n",
        "            plt.axis('off')\n",
        "\n",
        "            plt.subplot(1, 2, 2)\n",
        "            plt.imshow(mask_np, cmap='gray')\n",
        "            plt.title(\"Mask\")\n",
        "            plt.axis('off')\n",
        "\n",
        "            plt.show()"
      ],
      "metadata": {
        "id": "0x4tJb8m15K9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xf4d8RAR5WC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# arquivo data.py\n",
        "import cv2\n",
        "from glob import glob\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "class Data(Dataset):\n",
        "    def __init__(self, image_dir: str, split: str, transform=None) -> None:\n",
        "        self.image_dir = image_dir\n",
        "        self.split = split\n",
        "        self.transform = transform\n",
        "        self.images = glob(f\"{image_dir}/{split}/patient103-frame01nii/*.jpg\")  # Ajuste o caminho conforme necessário\n",
        "        self.masks = glob(f\"{image_dir}/{split}/patient103-frame01-gtnii/*.jpg\")    # Ajuste o caminho conforme necessário\n",
        "\n",
        "        # Verifique se temos a mesma quantidade de imagens e máscaras\n",
        "        assert len(self.images) == len(self.masks), \"Número de imagens e máscaras não corresponde\"\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> tuple:\n",
        "        # Carregar imagem e máscara\n",
        "        image_path = self.images[idx]\n",
        "        mask_path = self.masks[idx]\n",
        "\n",
        "        # Carregar a imagem e a máscara em escala de cinza (para o caso de máscaras)\n",
        "        image = cv2.imread(image_path)\n",
        "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        # Aplicar transformações, se especificadas\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=image, mask=mask)\n",
        "            image = augmented['image']\n",
        "            mask = augmented['mask']\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "class Dataloader:\n",
        "    def __init__(self, batch_size: int, shuffle: bool, size: int, subset: int = 0, description: bool = False) -> None:\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.size = size\n",
        "        self.subset = subset\n",
        "        self.description = description\n",
        "\n",
        "    def compose(self):\n",
        "        return A.Compose([\n",
        "            A.Resize(self.size, self.size),\n",
        "            A.Normalize(),\n",
        "            ToTensorV2()\n",
        "        ])\n",
        "\n",
        "    def get_dataloader(self, split: str) -> DataLoader:\n",
        "        dataset = Data(image_dir=\"path/to/images\", split=split, transform=self.compose())\n",
        "        if len(dataset) == 0:\n",
        "            raise ValueError(f\"O dataset {split} está vazio. Verifique o caminho das imagens e das máscaras.\")\n",
        "        return DataLoader(dataset, batch_size=self.batch_size, shuffle=self.shuffle)\n",
        "\n",
        "    def get_train_dataloader(self) -> DataLoader:\n",
        "        return self.get_dataloader('train')\n",
        "\n",
        "    def get_val_dataloader(self) -> DataLoader:\n",
        "        return self.get_dataloader('val')\n",
        "\n",
        "    def get_test_dataloader(self) -> DataLoader:\n",
        "        return self.get_dataloader('test')\n",
        "\n",
        "# arquivo main.py\n",
        "if __name__ == '__main__':\n",
        "    dataloader = Dataloader(batch_size=2, size=512, shuffle=True, description=True)\n",
        "\n",
        "    train_dataloader = dataloader.get_train_dataloader()\n",
        "\n",
        "    EPOCHS = 10\n",
        "    for epoch in range(EPOCHS):\n",
        "        for image, mask in train_dataloader:\n",
        "            image = image.detach().cpu().numpy()[0].transpose(1, 2, 0)\n",
        "            mask = mask.detach().cpu().numpy()[0]\n",
        "            plt.imshow(image)\n",
        "            plt.show()\n",
        "            plt.imshow(mask, cmap='gray')\n",
        "            plt.show()"
      ],
      "metadata": {
        "id": "d522jkN5EHKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "\n",
        "def display_images(image_dir, mask_dir, num_images=5):\n",
        "    \"\"\"Função para exibir imagens e máscaras correspondentes.\"\"\"\n",
        "    image_paths = sorted(glob(os.path.join(image_dir, \"*.jpg\")))[:num_images]\n",
        "    mask_paths = sorted(glob(os.path.join(mask_dir, \"*.png\")))[:num_images]\n",
        "\n",
        "    for img_path, mask_path in zip(image_paths, mask_paths):\n",
        "        # Carregar imagem e máscara\n",
        "        image = cv2.imread(img_path)\n",
        "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)  # Carregar em escala de cinza\n",
        "\n",
        "        # Converter imagem para RGB\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Exibir imagem e máscara lado a lado\n",
        "        plt.figure(figsize=(10, 5))\n",
        "\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.imshow(image)\n",
        "        plt.title(\"Imagem\")\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.imshow(mask, cmap=\"gray\")\n",
        "        plt.title(\"Máscara\")\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "# Caminhos para diretórios de treino, validação e teste\n",
        "train_images_dir = \"/content/drive/MyDrive/patient103-frame01nii\"\n",
        "train_masks_dir = \"patient103-frame01-gtnii\"\n",
        "\n",
        "val_images_dir = \"/content/drive/MyDrive/patient103-frame01nii\"\n",
        "val_masks_dir = \"/patient103-frame01-gtnii\"\n",
        "\n",
        "test_images_dir = \"/content/drive/MyDrive/patient103-frame01nii\"\n",
        "test_masks_dir = \"patient103-frame01-gtnii\"\n",
        "\n",
        "# Exibir imagens de treino\n",
        "print(\"Treinamento:\")\n",
        "display_images(train_images_dir, train_masks_dir)\n",
        "\n",
        "# Exibir imagens de validação\n",
        "print(\"Validação:\")\n",
        "display_images(val_images_dir, val_masks_dir)\n",
        "\n",
        "# Exibir imagens de teste\n",
        "print(\"Teste:\")\n",
        "display_images(test_images_dir, test_masks_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_KtqU7srnQ-",
        "outputId": "5bef0fd6-c214-4a4b-91d3-3f4b751c427f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treinamento:\n",
            "Validação:\n",
            "Teste:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "\n",
        "def display_images(image_dir, mask_dir, num_images=5):\n",
        "    \"\"\"Função para exibir imagens e máscaras correspondentes com informações adicionais.\"\"\"\n",
        "    image_paths = sorted(glob(os.path.join(image_dir, \"*.jpg\")))[:num_images]\n",
        "    mask_paths = sorted(glob(os.path.join(mask_dir, \"*.png\")))[:num_images]\n",
        "\n",
        "    for img_path, mask_path in zip(image_paths, mask_paths):\n",
        "        # Carregar imagem e máscara\n",
        "        image = cv2.imread(img_path)\n",
        "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)  # Carregar em escala de cinza\n",
        "\n",
        "        # Converter imagem para RGB\n",
        "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Obter informações\n",
        "        img_shape = image.shape\n",
        "        mask_shape = mask.shape\n",
        "        mask_pixels = cv2.countNonZero(mask)  # Conta os pixels diferentes de zero (assumindo que 0 seja fundo)\n",
        "\n",
        "        # Exibir imagem e máscara lado a lado com informações\n",
        "        plt.figure(figsize=(10, 5))\n",
        "\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.imshow(image_rgb)\n",
        "        plt.title(f\"Imagem - Dimensões: {img_shape}\")\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.imshow(mask, cmap=\"gray\")\n",
        "        plt.title(f\"Máscara - Dimensões: {mask_shape} | Pixels Máscara: {mask_pixels}\")\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "# Caminhos para diretórios de treino, validação e teste\n",
        "train_images_dir = \"/content/drive/MyDrive/patient103-frame01nii\"\n",
        "train_masks_dir = \"/content/drive/MyDrive/patient110-4dnii\"\n",
        "\n",
        "val_images_dir = \"/content/drive/MyDrive/patient103-frame01nii\"\n",
        "val_masks_dir = \"/content/drive/MyDrive/patient110-4dnii\"\n",
        "\n",
        "test_images_dir = \"/content/drive/MyDrive/patient103-frame01nii\"\n",
        "test_masks_dir = \"/content/drive/MyDrive/patient110-4dnii\"\n",
        "\n",
        "# Exibir imagens de treino\n",
        "print(\"Treinamento:\")\n",
        "display_images(train_images_dir, train_masks_dir)\n",
        "\n",
        "# Exibir imagens de validação\n",
        "print(\"Validação:\")\n",
        "display_images(val_images_dir, val_masks_dir)\n",
        "\n",
        "# Exibir imagens de teste\n",
        "print(\"Teste:\")\n",
        "display_images(test_images_dir, test_masks_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBBpZdENtWoF",
        "outputId": "147dfcbe-8254-4787-8ae1-399c0ef83688"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treinamento:\n",
            "Validação:\n",
            "Teste:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "class Data(Dataset):\n",
        "    def __init__(self, image_dir: str, mask_dir: str, transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.mask_dir = mask_dir\n",
        "        self.transform = transform\n",
        "        self.image_paths = sorted(glob(os.path.join(image_dir, \"*.jpg\")))\n",
        "        self.mask_paths = sorted(glob(os.path.join(mask_dir, \"*.png\")))\n",
        "\n",
        "        assert len(self.image_paths) == len(self.mask_paths), \"O número de imagens e máscaras não coincide.\"\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        image = cv2.imread(self.image_paths[idx])\n",
        "        mask = cv2.imread(self.mask_paths[idx], cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=image, mask=mask)\n",
        "            image = augmented['image']\n",
        "            mask = augmented['mask']\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "class Dataloader:\n",
        "    def __init__(self, batch_size: int, image_dir: str, mask_dir: str, shuffle: bool = True, transform=None):\n",
        "        self.batch_size = batch_size\n",
        "        self.dataset = Data(image_dir, mask_dir, transform)\n",
        "        self.data_loader = DataLoader(self.dataset, batch_size=self.batch_size, shuffle=shuffle)\n",
        "\n",
        "    def get_dataloader(self):\n",
        "        return self.data_loader\n",
        "\n",
        "# Função para exibir imagens e máscaras\n",
        "def display_images(data_loader, num_images=5):\n",
        "    for i, (images, masks) in enumerate(data_loader):\n",
        "        if i >= num_images:  # Limitar o número de imagens exibidas\n",
        "            break\n",
        "\n",
        "        for j in range(images.size(0)):\n",
        "            image = images[j].numpy().transpose(1, 2, 0)  # Transpor para formato HWC\n",
        "            mask = masks[j].numpy()  # Converter máscara para numpy\n",
        "\n",
        "            plt.figure(figsize=(10, 5))\n",
        "            plt.subplot(1, 2, 1)\n",
        "            plt.imshow(image)\n",
        "            plt.title(\"Imagem\")\n",
        "            plt.axis(\"off\")\n",
        "\n",
        "            plt.subplot(1, 2, 2)\n",
        "            plt.imshow(mask, cmap=\"gray\")\n",
        "            plt.title(\"Máscara\")\n",
        "            plt.axis(\"off\")\n",
        "\n",
        "            plt.show()\n",
        "\n",
        "# Configurações\n",
        "train_images_dir = \"/content/drive/MyDrive/patient103-frame01nii\"\n",
        "train_masks_dir = \"patient103-frame01-gtnii\"\n",
        "\n",
        "transform = A.Compose([\n",
        "    A.Resize(256, 256),  # Redimensionar imagens\n",
        "    ToTensorV2(),  # Converter para tensor PyTorch\n",
        "])\n",
        "\n",
        "# Criação do DataLoader\n",
        "dataloader = Dataloader(batch_size=2, image_dir=train_images_dir, mask_dir=train_masks_dir, transform=transform)\n",
        "\n",
        "# Exibir imagens e máscaras\n",
        "display_images(dataloader.get_dataloader(), num_images=5)"
      ],
      "metadata": {
        "id": "E4Df2YCruxBR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}