{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1J3InRb7TtWysUXjCmhyGvwsKv_-LXB1_",
      "authorship_tag": "ABX9TyOuZb8wxK8EG/VIHEirdW2R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alan240124/Alan/blob/main/Matricas(2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4kdAwyNzprE",
        "outputId": "448a343f-9b64-4b33-c798-427f8b88cef6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de imagens no dataset: 9\n",
            "Tamanho do batch de imagens: torch.Size([4, 1, 256, 256])\n",
            "Tamanho do batch de máscaras: torch.Size([4, 1, 256, 256])\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "class HeartDataset(Dataset):\n",
        "    def __init__(self, image_dir, mask_dir, transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.mask_dir = mask_dir\n",
        "        self.transform = transform\n",
        "        self.images = sorted(os.listdir(image_dir))\n",
        "        self.masks = sorted(os.listdir(mask_dir))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = os.path.join(self.image_dir, self.images[idx])\n",
        "        mask_path = os.path.join(self.mask_dir, self.masks[idx])\n",
        "\n",
        "        image = Image.open(image_path).convert(\"L\")  # Converter para grayscale\n",
        "        mask = Image.open(mask_path).convert(\"L\")    # Converter para grayscale\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "            mask = self.transform(mask)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "\n",
        "# Diretórios das imagens e máscaras\n",
        "image_dir = '/content/drive/MyDrive/DataSet3/images'  # Substitua pelo caminho real\n",
        "mask_dir = '/content/drive/MyDrive/DataSet3/masks'    # Substitua pelo caminho real\n",
        "\n",
        "# Transformação (exemplo: converter para tensor)\n",
        "#transform = transforms.ToTensor()\n",
        "# Transforma as imagens para tensor e normaliza\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),  # Redimensione conforme necessário\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Criação do dataset e do DataLoader\n",
        "dataset = HeartDataset(image_dir, mask_dir, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
        "\n",
        "# Exibir algumas informações do dataset\n",
        "print(f\"Total de imagens no dataset: {len(dataset)}\")\n",
        "\n",
        "# Exemplo de iteração pelo DataLoader\n",
        "for images, masks in dataloader:\n",
        "    print(f\"Tamanho do batch de imagens: {images.shape}\")\n",
        "    print(f\"Tamanho do batch de máscaras: {masks.shape}\")\n",
        "    break  # Apenas um batch para demonstração"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(UNet, self).__init__()\n",
        "\n",
        "        def conv_block(in_channels, out_channels):\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "                nn.ReLU(inplace=True)\n",
        "            )\n",
        "\n",
        "        self.encoder1 = conv_block(1, 64)\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "        self.encoder2 = conv_block(64, 128)\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "        self.encoder3 = conv_block(128, 256)\n",
        "        self.pool3 = nn.MaxPool2d(2)\n",
        "        self.encoder4 = conv_block(256, 512)\n",
        "        self.pool4 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.bottleneck = conv_block(512, 1024)\n",
        "\n",
        "        self.upconv4 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
        "        self.decoder4 = conv_block(1024, 512)\n",
        "        self.upconv3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
        "        self.decoder3 = conv_block(512, 256)\n",
        "        self.upconv2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
        "        self.decoder2 = conv_block(256, 128)\n",
        "        self.upconv1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
        "        self.decoder1 = conv_block(128, 64)\n",
        "\n",
        "        self.conv_last = nn.Conv2d(64, 1, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        e1 = self.encoder1(x)\n",
        "        e2 = self.encoder2(self.pool1(e1))\n",
        "        e3 = self.encoder3(self.pool2(e2))\n",
        "        e4 = self.encoder4(self.pool3(e3))\n",
        "\n",
        "        b = self.bottleneck(self.pool4(e4))\n",
        "\n",
        "        d4 = self.upconv4(b)\n",
        "        d4 = torch.cat((d4, e4), dim=1)\n",
        "        d4 = self.decoder4(d4)\n",
        "        d3 = self.upconv3(d4)\n",
        "        d3 = torch.cat((d3, e3), dim=1)\n",
        "        d3 = self.decoder3(d3)\n",
        "        d2 = self.upconv2(d3)\n",
        "        d2 = torch.cat((d2, e2), dim=1)\n",
        "        d2 = self.decoder2(d2)\n",
        "        d1 = self.upconv1(d2)\n",
        "        d1 = torch.cat((d1, e1), dim=1)\n",
        "        d1 = self.decoder1(d1)\n",
        "\n",
        "        return torch.sigmoid(self.conv_last(d1))\n",
        "\n",
        "# Inicializar o modelo e definir o otimizador e a função de perda\n",
        "model = UNet()\n",
        "criterion = nn.BCELoss()  # Usamos BCELoss para segmentação binária\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "N1zb66fv1KCp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuração do dispositivo (GPU se disponível)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "\n",
        "# Loop de treinamento\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    for images, masks in dataloader:\n",
        "        images = images.to(device)\n",
        "        masks = masks.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, masks)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss/len(dataloader)}\")\n",
        "\n",
        "    # Salva o modelo após cada epoch\n",
        "    torch.save(model.state_dict(), f\"unet_epoch_{epoch+1}.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcS4sfDv1Tmj",
        "outputId": "cd99ae92-f0df-43b3-e861-3313424b91ec"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.09899218877156575\n",
            "Epoch [2/10], Loss: 0.0978844886024793\n",
            "Epoch [3/10], Loss: 0.09699309120575587\n",
            "Epoch [4/10], Loss: 0.1113407239317894\n",
            "Epoch [5/10], Loss: 0.09998705983161926\n",
            "Epoch [6/10], Loss: 0.09798662116130193\n",
            "Epoch [7/10], Loss: 0.10053092737992604\n",
            "Epoch [8/10], Loss: 0.09873532503843307\n",
            "Epoch [9/10], Loss: 0.0925753836830457\n",
            "Epoch [10/10], Loss: 0.08920158445835114\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_coefficient(pred, target, epsilon=1e-6):\n",
        "    intersection = (pred * target).sum()\n",
        "    return (2. * intersection + epsilon) / (pred.sum() + target.sum() + epsilon)\n",
        "\n",
        "# Exemplo de uso com uma batch do DataLoader\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for images, masks in dataloader:\n",
        "        images = images.to(device)\n",
        "        masks = masks.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        dice = dice_coefficient(outputs, masks)\n",
        "        print(\"DICE coefficient:\", dice.item())\n",
        "        break  # Apenas para uma batch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-oAHsFVJbBJ",
        "outputId": "90aeceeb-1ffc-41e1-e258-0d1ddeada650"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DICE coefficient: 0.8818418979644775\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# Função de cálculo do DICE coefficient\n",
        "def dice_coefficient(pred, target, epsilon=1e-6):\n",
        "    pred = (pred > 0.5).float()  # Binarizar a predição\n",
        "    target = (target > 0.5).float()  # Binarizar a máscara\n",
        "    intersection = (pred * target).sum()  # Calcular a interseção\n",
        "    return (2. * intersection + epsilon) / (pred.sum() + target.sum() + epsilon)  # Fórmula do DICE\n",
        "\n",
        "# Função de cálculo da Intersection over Union (IoU)\n",
        "def iou_score(pred, target, epsilon=1e-6):\n",
        "    pred = (pred > 0.5).float()\n",
        "    target = (target > 0.5).float()\n",
        "    intersection = (pred * target).sum()  # Interseção\n",
        "    union = pred.sum() + target.sum() - intersection  # União\n",
        "    return (intersection + epsilon) / (union + epsilon)  # Fórmula do IoU\n",
        "\n",
        "# Função de cálculo da Accuracy\n",
        "def accuracy_score(pred, target):\n",
        "    pred = (pred > 0.5).float()  # Binarizar a predição\n",
        "    target = (target > 0.5).float()  # Binarizar a máscara\n",
        "    correct = (pred == target).sum()  # Contar acertos\n",
        "    total = target.numel()  # Total de pixels\n",
        "    return correct / total  # Proporção de acertos\n",
        "\n",
        "# Exemplo de uso com uma batch do DataLoader\n",
        "model.eval()  # Coloca o modelo em modo de avaliação\n",
        "with torch.no_grad():  # Desliga o cálculo de gradientes\n",
        "    for images, masks in dataloader:  # Loop sobre as batches\n",
        "        images = images.to(device)  # Mover para o dispositivo (GPU ou CPU)\n",
        "        masks = masks.to(device)\n",
        "\n",
        "        # Passando as imagens pela rede\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Calcular as métricas\n",
        "        dice = dice_coefficient(outputs, masks)  # DICE coefficient\n",
        "        iou = iou_score(outputs, masks)  # IoU\n",
        "        accuracy = accuracy_score(outputs, masks)  # Accuracy\n",
        "\n",
        "        # Exibindo os resultados\n",
        "        print(f\"DICE coefficient: {dice.item():.4f}\")\n",
        "        print(f\"IoU score: {iou.item():.4f}\")\n",
        "        print(f\"Accuracy: {accuracy.item():.4f}\")\n",
        "\n",
        "        break  # Apenas para uma batch, remova esta linha para calcular para todas as batches\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkKvoZEpLEUc",
        "outputId": "c142305c-6a9f-408d-cdfe-4d8c72c0e259"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DICE coefficient: 0.9163\n",
            "IoU score: 0.8456\n",
            "Accuracy: 0.9706\n"
          ]
        }
      ]
    }
  ]
}